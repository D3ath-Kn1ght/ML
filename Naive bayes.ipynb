{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPB5arEBy6CT/U/dEkbh83L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","DatasetBaseFolder = '/content/gdrive/My Drive/Colab Notebooks/Dataset/'\n","import numpy as np \n","import pandas as pd \t\n","import matplotlib.pyplot as plt \n","import math\n","\n","\n","def accuracy_score(y_true, y_pred):\n","#score = (y_true - y_pred) / len(y_true)\n","\treturn round(float(sum(y_pred == y_true))/float(len(y_true)) * 100 ,2)\n","\n","def pre_processing(df):\n","# partioning data into features and target\n","\tX = df.drop([df.columns[-1]], axis = 1)\n","\ty = df[df.columns[-1]]\n","\treturn X, y\n","\n","\n","\n","class  NaiveBayes:\n","\tdef __init__(self):\n","\n","\t\t\"\"\"\n","\t\t\tAttributes:\n","\t\t\t\tlikelihoods: Likelihood of each feature per class\n","\t\t\t\tclass_priors: Prior probabilities of classes \n","\t\t\t\tpred_priors: Prior probabilities of features \n","\t\t\t\tfeatures: All features of dataset\n","\n","\t\t\"\"\"\n","\t\tself.features = list\n","\t\tself.likelihoods = {}\n","\t\tself.class_priors = {}\n","\t\tself.pred_priors = {}\n","\n","\t\tself.X_train = np.array\n","\t\tself.y_train = np.array\n","\t\tself.train_size = int\n","\t\tself.num_feats = int\n","\n","\tdef fit(self, X, y):\n","\n","\t\tself.features = list(X.columns)\n","\t\tself.X_train = X\n","\t\tself.y_train = y\n","\t\tself.train_size = X.shape[0]\n","\t\tself.num_feats = X.shape[1]\n","\n","\t\tfor feature in self.features:\n","\t\t\tself.likelihoods[feature] = {}\n","\t\t\tself.pred_priors[feature] = {}\n","\n","\t\t\tfor feat_val in np.unique(self.X_train[feature]):\n","\t\t\t\tself.pred_priors[feature].update({feat_val: 0})\n","\n","\t\t\t\tfor outcome in np.unique(self.y_train):\n","\t\t\t\t\tself.likelihoods[feature].update({feat_val+'_'+outcome:0})\n","\t\t\t\t\tself.class_priors.update({outcome: 0})\n","\n","\t\tself._calc_class_prior()\n","\t\tself._calc_likelihoods()\n","\t\tself._calc_predictor_prior()\n","\n","\tdef _calc_class_prior(self):\n","\n","\t\t#P(c) - Prior Class Probability\n","\t\tfor outcome in np.unique(self.y_train):\n","\t\t\toutcome_count = sum(self.y_train == outcome)\n","\t\t\tself.class_priors[outcome] = outcome_count / self.train_size\n","\n","\n","\tdef _calc_likelihoods(self):\n","   \n","\t\t#P(x|c) - Likelihood\n","\t\tfor feature in self.features:\n","\t\t\tfor outcome in np.unique(self.y_train):\n","\t\t\t\toutcome_count = sum(self.y_train == outcome)\n","\t\t\t\tfeat_likelihood = self.X_train[feature][self.y_train[self.y_train == outcome].index.values.tolist()].value_counts().to_dict()\n","\t\t\t\tfor feat_val, count in feat_likelihood.items():\n","\t\t\t\t\tself.likelihoods[feature][feat_val + '_' + outcome] = count/outcome_count\n","\n","\n","\tdef _calc_predictor_prior(self):\n","\n","\t\t# P(x) - Evidence \n","\t\tfor feature in self.features:\n","\t\t\tfeat_vals = self.X_train[feature].value_counts().to_dict()\n","\t\t\tfor feat_val, count in feat_vals.items():\n","\t\t\t\tself.pred_priors[feature][feat_val] = count/self.train_size\n","\n","\n","\tdef predict(self, X):\n","\n","\t\t# Calculates Posterior probability P(c|x)\n","\t\tresults = []\n","\t\tX = np.array(X)\n","\n","\t\tfor query in X:\n","\t\t\tprobs_outcome = {}\n","\t\t\tfor outcome in np.unique(self.y_train):\n","\t\t\t\tprior = self.class_priors[outcome]\n","\t\t\t\tlikelihood = 1\n","\t\t\t\tevidence = 1\n","\t\t\t\tfor feat, feat_val in zip(self.features, query):\n","\t\t\t\t\tlikelihood *= self.likelihoods[feat][feat_val + '_' + outcome]\n","\t\t\t\t\tevidence *= self.pred_priors[feat][feat_val]\n","\t\t\t\tposterior = (likelihood * prior) / (evidence)\n","\t\t\t\tprobs_outcome[outcome] = posterior\n","      \n","\t\t\tresult = max(probs_outcome, key = lambda x: probs_outcome[x])\n","\t\t\tresults.append(result)\n","\t\treturn np.array(results)\n","\n","\n","#Main Body of the Program\n","\n","\n","\t#Weather Dataset\n","\tprint(\"\\nWeather Dataset:\")\n","\tdf = pd.read_csv(DatasetBaseFolder+\"weather.csv\")\n","\t#print(df)\n","\n","\t#Split fearures and target\n","\tX,y  = pre_processing(df)\n","\n","\tnb_clf = NaiveBayes()\n","\tnb_clf.fit(X, y)\n","\n","\tprint(\"Train Accuracy: {}\".format(accuracy_score(y, nb_clf.predict(X))))\n","\t\n","\t#Query 1:\n","\tquery = np.array([['Rainy','Mild', 'Normal', 't']])\n","\tprint(\"Query 1:- {} ---> {}\".format(query, nb_clf.predict(query)))\n","\n","\t#Query 2:\n","\tquery = np.array([['Overcast','Cool', 'Normal', 't']])\n","\tprint(\"Query 2:- {} ---> {}\".format(query, nb_clf.predict(query)))\n","\n","\t#Query 3:\n","\tquery = np.array([['Sunny','Hot', 'High', 't']])\n","\tprint(\"Query 3:- {} ---> {}\".format(query, nb_clf.predict(query)))\n"," \n","  #Query 4:\n","\tquery = np.array([['Sunny','Cool', 'High', 'f']])\n","\tprint(\"Query 4:- {} ---> {}\".format(query, nb_clf.predict(query)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":409},"id":"Yg3I8cuqSqfp","executionInfo":{"status":"error","timestamp":1681897237376,"user_tz":-330,"elapsed":25851,"user":{"displayName":"Dread Xtra","userId":"08540451915987474529"}},"outputId":"6eb3f231-47a4-4829-bdf0-83469d1be529"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","\n","Weather Dataset:\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3a1d25802205>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mclass\u001b[0m  \u001b[0mNaiveBayes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-3a1d25802205>\u001b[0m in \u001b[0;36mNaiveBayes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpre_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mnb_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mnb_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'NaiveBayes' is not defined"]}]}]}